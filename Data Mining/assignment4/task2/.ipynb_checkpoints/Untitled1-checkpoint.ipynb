{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time \n",
    "import winsound \n",
    "import numpy as np\n",
    "import scipy.sparse as sp_sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.datasets as sk_data\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import sklearn.utils as utils\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTagsHandles(x):\n",
    "    symbols = [' ', '\\n', ',', '.', '/', '//', '&', '?', ';', '[', ']', '!', ':', 'â€¢', '\\\\', ')']\n",
    "    index = 0\n",
    "    word = \"\"\n",
    "    hh = []\n",
    "    \n",
    "    while(index < len(x)):\n",
    "        if(x[index] == \"@\" or x[index] == \"#\"):\n",
    "            if(word == \"\"):\n",
    "                word = word + x[index]\n",
    "            else:\n",
    "                if(len(word) == 1):\n",
    "                    word = \"\" + x[index]\n",
    "                else:\n",
    "                    hh.append(word)\n",
    "                    word = \"\"\n",
    "                    continue\n",
    "        elif(x[index] in symbols or ord(x[index]) == 8230):\n",
    "            if(word != \"\"):\n",
    "                hh.append(word)\n",
    "                word = \"\"\n",
    "        else:\n",
    "            if(word == \"\"):\n",
    "                index = index + 1\n",
    "                continue\n",
    "            else:\n",
    "                word = word + x[index]\n",
    "\n",
    "        index = index + 1\n",
    "    if(len(word) > 1):\n",
    "        hh.append(word)\n",
    "        \n",
    "    return (hh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vriskw poion akolouthei kathe xrhsths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 1.363697177422523 seconds\n",
      "23716167 : 1\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "file = open(\"clinton_trump_user_classes.txt\", \"r\")\n",
    "\n",
    "nameIDAndFollow = {}\n",
    "\n",
    "for line in file:\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    text = line.split(\"\\t\")\n",
    "    nameIDAndFollow[str(text[0])] = int(text[1])\n",
    "\n",
    "end = time.clock()\n",
    "print(\"TIME: \" + str(end - start) + \" seconds\")\n",
    "\n",
    "for i in nameIDAndFollow:\n",
    "    print(i + \" : \" + str(nameIDAndFollow[i]))\n",
    "    break\n",
    "\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha vrw ta k = 10 kalytera hashtags/handles thw clinton kai tou trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n"
     ]
    }
   ],
   "source": [
    "file = open(\"dataTrain.txt\", \"r\")\n",
    "\n",
    "hashtagTrump = {}\n",
    "hashtagClinton = {}\n",
    "\n",
    "c = 0\n",
    "for line in file:\n",
    "    c = c + 1\n",
    "    line = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "    hhList = getTagsHandles(line[-1]) + getTagsHandles(line[6])\n",
    "    for i in hhList:\n",
    "        if(nameIDAndFollow[line[2]] == 0):\n",
    "            if(i in hashtagTrump):\n",
    "                hashtagTrump[i] = hashtagTrump[i] + 1\n",
    "            else:\n",
    "                hashtagTrump[i] = 1\n",
    "        else:\n",
    "            if(i in hashtagClinton):\n",
    "                hashtagClinton[i] = hashtagClinton[i] + 1\n",
    "            else:\n",
    "                hashtagClinton[i] = 1\n",
    "    if(c % 100000 == 0):\n",
    "        print(c)\n",
    "\n",
    "file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#taxinomhsh me vash thn timh -1 se fuinousa seira\n",
    "import operator\n",
    "\n",
    "topTrump = []\n",
    "topClinton = []\n",
    "\n",
    "sorted_topTrump = sorted(hashtagTrump.items(), key=operator.itemgetter(1))\n",
    "sorted_topClinton = sorted(hashtagClinton.items(), key=operator.itemgetter(1))\n",
    "\n",
    "sorted_topTrump = sorted_topTrump[::-1]\n",
    "sorted_topClinton = sorted_topClinton[::-1]\n",
    "\n",
    "for i in range(100):\n",
    "    topClinton.append(sorted_topClinton[i][0])\n",
    "    topTrump.append(sorted_topTrump[i][0])\n",
    "    \n",
    "topTrump = set(topTrump)\n",
    "topClinton = set(topClinton)\n",
    "#hashtagTrump = {}\n",
    "#hashtagClinton = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n"
     ]
    }
   ],
   "source": [
    "X_TRAIN = []\n",
    "\n",
    "file = open(\"hashtags.txt\", \"r\")\n",
    "Y_TRAIN = []\n",
    "\n",
    "c = 0\n",
    "for line in file:\n",
    "    c = c + 1\n",
    "    line = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "    newIn = {}\n",
    "    for i in range(len(line)):\n",
    "        if(line [i] in topTrump or line[i] in topClinton):\n",
    "            newIn[line[i]] = 1\n",
    "    X_TRAIN.append(newIn)\n",
    "    if(c % 100000 == 0):\n",
    "        print(c)\n",
    "\n",
    "file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n"
     ]
    }
   ],
   "source": [
    "file = open(\"dataTrain.txt\", \"r\")\n",
    "\n",
    "c = 0\n",
    "for line in file:\n",
    "    c = c + 1\n",
    "    line = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "    Y_TRAIN.append(nameIDAndFollow[line[2]])\n",
    "    if(c % 100000 == 0):\n",
    "        print(c)\n",
    "        \n",
    "file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "XTRAIN = vec.fit_transform(X_TRAIN)\n",
    "vec.get_feature_names()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree = dtree.fit(XTRAIN, Y_TRAIN)\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sto arxeio \"hashtags.txt\" tha apothikeursw ta hashtags/handles pou xrhsimopoiei kathe xrhsths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n"
     ]
    }
   ],
   "source": [
    "file = open(\"dataTrain.txt\", \"r\")\n",
    "hashtagsFile = open(\"hashtags.txt\", \"w\")\n",
    "\n",
    "c = 0\n",
    "for line in file:\n",
    "    c = c + 1\n",
    "    line = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "    hhList = getTagsHandles(line[-1]) + getTagsHandles(line[6])\n",
    "    hashtagsFile.write(line[2] + \"\\t\")\n",
    "    for i in hhList:\n",
    "        hashtagsFile.write(i + \"\\t\")\n",
    "    hashtagsFile.write(\"\\n\")\n",
    "    if(c % 100000 == 0):\n",
    "        print(c)\n",
    "\n",
    "file.close()\n",
    "hashtagsFile.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairnw ta dedomena gia test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n"
     ]
    }
   ],
   "source": [
    "fileTest = open(\"clinton_trump_kaggle_test.txt\", \"r\")\n",
    "\n",
    "idUsers = []\n",
    "X_TEST = []\n",
    "\n",
    "c = 0\n",
    "for line in fileTest:\n",
    "    c = c + 1\n",
    "    line = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "    idUsers.append(line[2])\n",
    "    hhList = getTagsHandles(line[-1]) + getTagsHandles(line[6])\n",
    "    newIn = {}\n",
    "    for i in range(0, len(hhList)):\n",
    "        if(hhList[i] in topTrump or hhList[i] in topClinton):\n",
    "            newIn[hhList[i]] = 1\n",
    "    X_TEST.append(newIn)\n",
    "    if(c % 100000 == 0):\n",
    "        print(c)\n",
    "        \n",
    "fileTest.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = DictVectorizer()\n",
    "XTEST = vec.fit_transform(X_TEST)\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 180 and input n_features is 179 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-072844836602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_PRED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTEST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 180 and input n_features is 179 "
     ]
    }
   ],
   "source": [
    "Y_PRED = dtree.predict(XTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddd = {}\n",
    "\n",
    "for i in range(len(idUsers)):\n",
    "    if(not(idUsers[i] in ddd)):\n",
    "        ddd[idUsers[i]] = Y_PRED[i]\n",
    "        \n",
    "print(len(ddd))\n",
    "Y_P = []\n",
    "ID_P = []\n",
    "\n",
    "for i in ddd:\n",
    "    ID_P.append(i)\n",
    "    Y_P.append(ddd[i])\n",
    "    \n",
    "import csv\n",
    "\n",
    "with open('results.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(ID_P)):\n",
    "        writer.writerow({'id': str(ID_P[i]), 'label': str(Y_P[i])})\n",
    "        \n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
