{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import winsound \n",
    "import numpy as np\n",
    "import scipy.sparse as sp_sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.datasets as sk_data\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import sklearn.utils as utils\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTagsHandles(x):\n",
    "    symbols = [' ', '\\n', ',', '.', '/', '//', '&', '?', ';', '[', ']', '!', ':', 'â€¢', '\\\\', ')']\n",
    "    index = 0\n",
    "    word = \"\"\n",
    "    hh = []\n",
    "    \n",
    "    while(index < len(x)):\n",
    "        if(x[index] == \"@\" or x[index] == \"#\"):\n",
    "            if(word == \"\"):\n",
    "                word = word + x[index]\n",
    "            else:\n",
    "                if(len(word) == 1):\n",
    "                    word = \"\" + x[index]\n",
    "                else:\n",
    "                    hh.append(word)\n",
    "                    word = \"\"\n",
    "                    continue\n",
    "        elif(x[index] in symbols or ord(x[index]) == 8230):\n",
    "            if(word != \"\"):\n",
    "                hh.append(word)\n",
    "                word = \"\"\n",
    "        else:\n",
    "            if(word == \"\"):\n",
    "                index = index + 1\n",
    "                continue\n",
    "            else:\n",
    "                word = word + x[index]\n",
    "\n",
    "        index = index + 1\n",
    "    if(len(word) > 1):\n",
    "        hh.append(word)\n",
    "        \n",
    "    return (hh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha vrw tous users pou exoun >10 kanei tweets kai na krathsw ta onomata tous. Tha ftiaxw ena arxeio opou mesa tha exei ta tweet gia to data train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME find counter of tweet: 134.30304958634224 seconds\n",
      "TIME find final user >10: 0.35527430338152044 seconds\n",
      "TIME write dataFIle: 284.70442661244306 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "file = open(\"clinton_trump_tweets.txt\", \"r\")\n",
    "counterTweet = {}\n",
    "\n",
    "for line in file:\n",
    "    line = line.replace('\\n', \"\")\n",
    "    splittedTweet = line.split(\"\\t\")\n",
    "    for items in range(len(splittedTweet)):\n",
    "        if(splittedTweet[items].isdigit()):\n",
    "            username = splittedTweet[items - 1]\n",
    "            if(username in counterTweet):\n",
    "                counterTweet[username] = counterTweet[username] + 1\n",
    "            else:\n",
    "                counterTweet[username] = 1\n",
    "            break\n",
    "            \n",
    "file.close()\n",
    "end = time.clock()\n",
    "print(\"TIME find counter of tweet: \" + str(end - start) + \" seconds\")\n",
    "winsound.Beep(450, 2000)\n",
    "\n",
    "start = time.clock()\n",
    "finalNames = []\n",
    "\n",
    "for i in counterTweet:\n",
    "    if(counterTweet[i] > 10):\n",
    "        finalNames.append(i)\n",
    "        \n",
    "finalNames = set(finalNames)\n",
    "end = time.clock()\n",
    "print(\"TIME find final user >10: \" + str(end - start) + \" seconds\")\n",
    "winsound.Beep(450, 2000)\n",
    "\n",
    "start = time.clock()\n",
    "fileToWrite = open(\"dataTrain.txt\", \"w\")\n",
    "file = open(\"clinton_trump_tweets.txt\", \"r\")\n",
    "\n",
    "for line in file:\n",
    "    prototypeLine = line\n",
    "    line = line.replace('\\n', \"\")\n",
    "    splittedTweet = line.split(\"\\t\")\n",
    "    for items in range(len(splittedTweet)):\n",
    "        if(splittedTweet[items].isdigit()):\n",
    "            username = splittedTweet[items - 1]\n",
    "            if(username in finalNames):\n",
    "                fileToWrite.write(prototypeLine)\n",
    "                \n",
    "file.close()\n",
    "fileToWrite.close()\n",
    "end = time.clock()\n",
    "print(\"TIME write dataFIle: \" + str(end - start) + \" seconds\")\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users: 70608\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of users: \" + str(len(finalNames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha diavasw to arxeio pou leei an enas user akolouthei ton trump h thn clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 1.4494455489659928 seconds\n",
      "23716167 : 1\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "file = open(\"clinton_trump_user_classes.txt\", \"r\")\n",
    "\n",
    "nameIDAndFollow = {}\n",
    "\n",
    "for line in file:\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    text = line.split(\"\\t\")\n",
    "    nameIDAndFollow[str(text[0])] = int(text[1])\n",
    "\n",
    "end = time.clock()\n",
    "print(\"TIME: \" + str(end - start) + \" seconds\")\n",
    "\n",
    "for i in nameIDAndFollow:\n",
    "    print(i + \" : \" + str(nameIDAndFollow[i]))\n",
    "    break\n",
    "\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha dedomena pou exei ena tweet einai ta akoloutha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : Cebel\n",
      "ScreenName : Cebel6\n",
      "UserID : 1519696717\n",
      "FollowersCount : 132\n",
      "FriendsCount : 263\n",
      "Location : Little Rock, Arkansas\n",
      "Description : Arkansas Razorback Fan Just trying to be #Uncommon one 1-0 day at a time.\n",
      "CreatedAt : Sat Oct 29 08:10:06 EEST 2016\n",
      "StatusID : 792232017094119425\n",
      "Language : en\n",
      "Place : null\n",
      "RetweetCount : 0\n",
      "FavoriteCount : 1\n",
      "Text : @NWAJimmy I've read it now though brother. Was pretty spot on Lots of bright spots but a lot to work on. Exactly as an exhibition should be!\n"
     ]
    }
   ],
   "source": [
    "file = open(\"dataTrain.txt\", \"r\")\n",
    "\n",
    "for line in file:\n",
    "    line = line.replace('\\n', \"\")\n",
    "    splittedTweet = line.split(\"\\t\")\n",
    "    l = \"Name, ScreenName, UserID, FollowersCount, FriendsCount, Location, Description, CreatedAt, StatusID, Language, Place, RetweetCount, FavoriteCount, Text\"\n",
    "    l = l.split(\", \")\n",
    "    for i in range(len(splittedTweet)):\n",
    "        print(l[i] + \" : \" + splittedTweet[i])\n",
    "    break\n",
    "    \n",
    "file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apo to data train tha parw kapoia pedia tou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 170.07063598102542 seconds\n",
      "Total numbe of kataxwrhseis sto data: 4760019\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "file = open(\"dataTrain.txt\", \"r\")\n",
    "data = set([])\n",
    "\n",
    "for line in file:\n",
    "    line = line.replace('\\n', \"\")\n",
    "    splittedTweet = line.split(\"\\t\")\n",
    "    userID = splittedTweet[2]\n",
    "    followersCount = splittedTweet[3]\n",
    "    friendsCount = splittedTweet[4]\n",
    "    location = splittedTweet[5]\n",
    "    description = splittedTweet[6]\n",
    "    createdAT = splittedTweet[7]\n",
    "    language = splittedTweet[9]\n",
    "    text = splittedTweet[-1]\n",
    "    newIn = [location, followersCount, friendsCount, description, createdAT, language, text, nameIDAndFollow[userID]]\n",
    "    data.add(str(newIn))\n",
    "\n",
    "file.close()\n",
    "end = time.clock()\n",
    "print(\"TIME: \" + str(end - start) + \" seconds\")\n",
    "sizeOfData = len(data)\n",
    "print(\"Total numbe of kataxwrhseis sto data: \" + str(sizeOfData))\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Exw na kane 5 cross validation. Tha ftiaxw ta arxeia gia train kai test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-101f12d2394f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwinsound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m450\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = open(\"data.txt\", \"w\")\n",
    "for i in data:\n",
    "    file.write(str(i) + \"\\n\")\n",
    "file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Start - End : 0 - 951980\n",
      "Test\n",
      "Start1 - End1 : 0 - 0\n",
      "Start2 - End2 : 951980 - 4759899\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Train\n",
      "Start - End : 951979 - 1903959\n",
      "Test\n",
      "Start1 - End1 : 0 - 951979\n",
      "Start2 - End2 : 1903959 - 4759899\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Train\n",
      "Start - End : 1903958 - 2855938\n",
      "Test\n",
      "Start1 - End1 : 0 - 1903958\n",
      "Start2 - End2 : 2855938 - 4759899\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Train\n",
      "Start - End : 2855937 - 3807917\n",
      "Test\n",
      "Start1 - End1 : 0 - 2855937\n",
      "Start2 - End2 : 3807917 - 4759899\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Train\n",
      "Start - End : 3807916 - 4759896\n",
      "Test\n",
      "Start1 - End1 : 0 - 3807916\n",
      "Start2 - End2 : 4759896 - 4759899\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "TIME: 416.07212727959904 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "size = int(sizeOfData / 5)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    trainFile = open(\"train\" + str(i + 1) + \".txt\", \"w\")\n",
    "    testFile = open(\"test\" + str(i + 1) + \".txt\", \"w\")\n",
    "    trainStart = i * size\n",
    "    trainEnd = i * size + size + 1\n",
    "    print(\"Train\")\n",
    "    print(\"Start - End : \" + str(trainStart) + \" - \" + str(trainEnd))\n",
    "    for j in range(trainStart, trainEnd):\n",
    "        testFile.write(data[j] + \"\\n\")\n",
    "    testStart1 = 0\n",
    "    testEnd1 = i * size\n",
    "    for j in range(testStart1, testEnd1):\n",
    "        trainFile.write(data[j] + \"\\n\")\n",
    "    testStart2 = i * size + size + 1\n",
    "    testEnd2 = sizeOfData\n",
    "    for j in range(testStart2, testEnd2):\n",
    "        trainFile.write(data[j] + \"\\n\")\n",
    "    print(\"Test\")\n",
    "    print(\"Start1 - End1 : \" + str(testStart1) + \" - \" + str(testEnd1))\n",
    "    print(\"Start2 - End2 : \" + str(testStart2) + \" - \" + str(testEnd2))\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    trainFile.close()\n",
    "    testFile.close()\n",
    "    winsound.Beep(450, 2000)\n",
    "\n",
    "end = time.clock()\n",
    "print(\"TIME: \" + str(end - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H epexergas;ia ginetai  mono sto train oxi sto test. Twra tha diavasw apo to arxeio train kai tha dhmiourghsw tis kataxwrhseis gia to X_TRAIN pou tha mpei ston classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Washington, D.C.', '418823', '2540', \"Host/managing editor of TV One's daily morning show, NewsOne Now; senior analyst, Tom Joyner Morning Show; author; international speaker; CEO, Nu Vision Media\", 'Thu Oct 27 04:01:34 EEST 2016', 'en', \"RT @Taniel: It's only 10/26, but Madison, WI has already broken its record for number of early votes cast in one cycle: https://t.co/qXf4db\", 1]\n"
     ]
    }
   ],
   "source": [
    "print(data[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def statistics(y_pred, y_test):\n",
    "    counter = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if(y_pred[i] == y_test[i]):\n",
    "            counter = counter + 1\n",
    "    pososto = counter * 100 / len(y_test)\n",
    "    print(\"POSOSTO: \" + str(pososto) + \" %\")\n",
    "    return(pososto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "ITERATION 0\n",
      "###############################\n",
      "10000\n",
      "50000\n",
      "200000\n",
      "500000\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "10000\n",
      "50000\n",
      "200000\n",
      "500000\n",
      "10000\n",
      "50000\n",
      "200000\n",
      "500000\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "POSOSTO: 85.49780457572638 %\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import time\n",
    "\n",
    "decisionTreePososto = []\n",
    "decisionTreeTime = []\n",
    "svmPososto = []\n",
    "svmTime = []\n",
    "logisticRegressionPososto = []\n",
    "logisticRegressionTime = []\n",
    "knnPososto = []\n",
    "knnTime = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(\"###############################\")\n",
    "    print(\"ITERATION \" + str(i))\n",
    "    print(\"###############################\")\n",
    "    locD = {}\n",
    "    lc = 0\n",
    "    dayD = {}\n",
    "    dc = 0\n",
    "    monthD = {}\n",
    "    mc = 0\n",
    "    hh = {}\n",
    "    \n",
    "    #------------------------------------------------------\n",
    "    #the vrw pososto gia ta hashtags/handles wste na ta xrhshmopoihsw san features\n",
    "    fileTrain = open(\"train\" + str(i + 1) + \".txt\", \"r\")\n",
    "    \n",
    "    xx = 0\n",
    "    for line in fileTrain:\n",
    "        xx = xx + 1\n",
    "        if(xx == 10000 or xx == 50000 or xx == 200000 or xx == 500000 or xx == 1000000 or xx == 2000000 or xx == 3000000):\n",
    "            print(xx)\n",
    "        line = ast.literal_eval(line)\n",
    "        follow = int(line[-1])\n",
    "        hhList = getTagsHandles(line[-2])\n",
    "        for j in hhList:\n",
    "            if(not(j in hh)):\n",
    "                hh[j] = [0, 0]\n",
    "                if(follow == 0):\n",
    "                    hh[j][0] = hh[j][0] + 1\n",
    "                else:\n",
    "                    hh[j][1] = hh[j][1] + 1\n",
    "            else:\n",
    "                if(follow == 0):\n",
    "                    hh[j][0] = hh[j][0] + 1\n",
    "                else:\n",
    "                    hh[j][1] = hh[j][1] + 1\n",
    "    xx = 0\n",
    "    for j in hh:\n",
    "        xx = xx + 1\n",
    "        if(xx == 10000 or xx == 50000 or xx == 200000 or xx == 500000 or xx == 1000000 or xx == 2000000 or xx == 3000000):\n",
    "            print(xx)\n",
    "        total = hh[j][0] + hh[j][1]\n",
    "        hh[j][0] = hh[j][0] / total\n",
    "        hh[j][1] = hh[j][1] / total\n",
    "        \n",
    "    fileTrain.close()\n",
    "    winsound.Beep(450, 2000)\n",
    "    #------------------------------------------------------\n",
    "    fileTrain = open(\"train\" + str(i + 1) + \".txt\", \"r\")\n",
    "    Y_TRAIN = []\n",
    "    X_TRAIN = []\n",
    "    \n",
    "    xx = 0\n",
    "    for line in fileTrain:\n",
    "        xx = xx + 1\n",
    "        if(xx == 10000 or xx == 50000 or xx == 200000 or xx == 500000 or xx == 1000000 or xx == 2000000 or xx == 3000000):\n",
    "            print(xx)\n",
    "        line = ast.literal_eval(line)\n",
    "        newInter = []\n",
    "        if(line[0] == \"\"):\n",
    "            locD[line[0]] = 0\n",
    "            location = 0\n",
    "        else:\n",
    "            if(not(line[0] in locD)):\n",
    "                lc = lc + 1\n",
    "                locD[line[0]] = lc\n",
    "                location = lc\n",
    "            else:\n",
    "                location = locD[line[0]]\n",
    "        time1 = line[2]\n",
    "        time1 = time1.split(\" \")\n",
    "        if(not(time1[0] in dayD)):\n",
    "            dc = dc + 1\n",
    "            dayD[time1[0]] = dc\n",
    "            day = dc\n",
    "        else:\n",
    "            day = dayD[time1[0]]\n",
    "        if(not(time1[1] in monthD)):\n",
    "            mc = mc + 1\n",
    "            monthD[time1[1]] = mc\n",
    "            month = mc\n",
    "        else:\n",
    "            month = monthD[time1[1]]\n",
    "        dayNumber = int(time1[2])\n",
    "        hashtagsList = getTagsHandles(line[-2])\n",
    "        sumHH = 0\n",
    "        for jj in hashtagsList:\n",
    "            sumHH = sumHH + hh[jj][0] - hh[jj][1]\n",
    "        \n",
    "        newInter.append(location)\n",
    "        newInter.append(day)\n",
    "        newInter.append(month)\n",
    "        newInter.append(dayNumber)\n",
    "        newInter.append(sumHH)\n",
    "        \n",
    "        #print(newInter)\n",
    "        X_TRAIN.append(newInter)\n",
    "        Y_TRAIN.append(int(line[-1]))\n",
    "        \n",
    "    fileTrain.close()\n",
    "    winsound.Beep(450, 2000)\n",
    "    #----------------------------------------------------\n",
    "    fileTest = open(\"test\" + str(i + 1) + \".txt\", \"r\")\n",
    "    Y_TEST = []\n",
    "    X_TEST = []\n",
    "    \n",
    "    for line in fileTest:\n",
    "        line = ast.literal_eval(line)\n",
    "        newInter = []\n",
    "        if(line[0] in locD):\n",
    "            location = locD[line[0]]\n",
    "        else:\n",
    "            lc = lc + 1\n",
    "            locD[line[0]] = lc\n",
    "            location = lc\n",
    "        time1 = line[2]\n",
    "        time1 = time1.split(\" \")\n",
    "        if(time1[0]in dayD):\n",
    "            day = dayD[time1[0]]\n",
    "        else:\n",
    "            dc = dc + 1\n",
    "            dayD[time1[0]] = dc\n",
    "            day = dc\n",
    "        if(time1[1] in monthD):\n",
    "            month = monthD[time1[1]]\n",
    "        else:\n",
    "            mc = mc + 1\n",
    "            monthD[time1[1]] = mc\n",
    "            month = mc\n",
    "        dayNumber = int(time1[2])\n",
    "        hashtagsList = getTagsHandles(line[-2])\n",
    "        sumHH = 0\n",
    "        for jj in hashtagsList:\n",
    "            if(jj in hh):\n",
    "                sumHH = sumHH + hh[jj][0] - hh[jj][1]\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        newInter.append(location)\n",
    "        newInter.append(day)\n",
    "        newInter.append(month)\n",
    "        newInter.append(dayNumber)\n",
    "        newInter.append(sumHH)\n",
    "        \n",
    "        #print(newInter)\n",
    "        X_TEST.append(newInter)\n",
    "        Y_TEST.append(int(line[-1]))\n",
    "        \n",
    "    fileTest.close()\n",
    "    winsound.Beep(450, 2000)\n",
    "    \n",
    "    #----------------------------------------------------\n",
    "    #decision tree\n",
    "    start = time.clock()\n",
    "    dtree = tree.DecisionTreeClassifier()\n",
    "    dtree = dtree.fit(X_TRAIN, Y_TRAIN)\n",
    "    Y_PRED = dtree.predict(X_TEST)\n",
    "    end = time.clock()\n",
    "    decisionTreePososto.append(statistics(Y_PRED, Y_TEST))\n",
    "    decisionTreeTime.append(end - start)\n",
    "    winsound.Beep(450, 2000)\n",
    "    \n",
    "    #----------------------------------------------------\n",
    "    #SVM\n",
    "    #start = time.clock()\n",
    "    #svm_clf = svm.SVC()\n",
    "    #svm_clf.fit(X_TRAIN,Y_TRAIN)\n",
    "    #Y_PRED = svm_clf.predict(X_TEST)\n",
    "    #end = time.clock()\n",
    "    #svmPososto.append(statistics(Y_PRED, Y_TEST))\n",
    "    #svmTime.append(end - start)\n",
    "    #winsound.Beep(450, 2000)\n",
    "    \n",
    "    #----------------------------------------------------\n",
    "    #LogisticRegression\n",
    "    start = time.clock()\n",
    "    lr_clf = linear_model.LogisticRegression()\n",
    "    lr_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "    Y_PRED = lr_clf.predict(X_TEST)\n",
    "    end = time.clock()\n",
    "    logisticRegressionPososto.append(statistics(Y_PRED, Y_TEST))\n",
    "    logisticRegressionTime.append(end - start)\n",
    "    winsound.Beep(450, 2000)\n",
    "    \n",
    "    #----------------------------------------------------\n",
    "    #k-nn\n",
    "    start = time.clock()\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_TRAIN,Y_TRAIN)\n",
    "    Y_PRED = knn.predict(X_TEST)\n",
    "    end = time.clock()\n",
    "    knnPososto.append(statistics(Y_PRED, Y_TEST))\n",
    "    knnTime.append(end - start)\n",
    "    winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "file = open(\"dataTrain.txt\", \"r\")\n",
    "D = []\n",
    "c = 0\n",
    "\n",
    "for line in file:\n",
    "    c = c + 1\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    splitt = line.split(\"\\t\")\n",
    "    hhList = getTagsHandles(splitt[-1])\n",
    "    D.append(Counter(hhList))\n",
    "    if(c % 100000 == 0):\n",
    "        print(c)\n",
    "file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"dataTrain.txt\", \"r\")\n",
    "categories = []\n",
    "c = 0\n",
    "\n",
    "for line in file:\n",
    "    c = c + 1\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    splitt = line.split(\"\\t\")\n",
    "    categories.append(nameIDAndFollow[str(splitt[2])])\n",
    "    if(c % 100000 == 0):\n",
    "        print(c)\n",
    "        \n",
    "file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 30, 330, 1148, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ast \n",
    "\n",
    "locD = {}\n",
    "lc = 0\n",
    "dayD = {}\n",
    "dc = 0\n",
    "monthD = {}\n",
    "mc = 0\n",
    "hh = {}\n",
    "hhC = 0\n",
    "langue = {}\n",
    "lanC = 0\n",
    "\n",
    "#------------------------------------------------------\n",
    "#the vrw pososto gia ta hashtags/handles wste na ta xrhshmopoihsw san features\n",
    "#fileTrain = data\n",
    "    \n",
    "#xx = 0\n",
    "#for line in fileTrain:\n",
    "#    xx = xx + 1\n",
    "#    if(xx == 10000 or xx == 50000 or xx == 200000 or xx == 500000 or xx == 1000000 or xx == 2000000 or xx == 3000000 or xx == 4000000):\n",
    "#        print(xx)\n",
    "#    line = ast.literal_eval(line)\n",
    "    #print(line)\n",
    "#    follow = int(line[-1])\n",
    "#    hhList = getTagsHandles(line[-2])\n",
    "#    for j in hhList:\n",
    "#        if(not(j in hh)):\n",
    "#            hh[j] = [0, 0]\n",
    "#            if(follow == 0):\n",
    "#                hh[j][0] = hh[j][0] + 1\n",
    "#            else:\n",
    "#                hh[j][1] = hh[j][1] + 1\n",
    "#        else:\n",
    "#            if(follow == 0):\n",
    "#                hh[j][0] = hh[j][0] + 1\n",
    "#            else:\n",
    "#                hh[j][1] = hh[j][1] + 1\n",
    "#xx = 0\n",
    "#for j in hh:\n",
    "#    xx = xx + 1\n",
    "#    if(xx == 10000 or xx == 50000 or xx == 200000 or xx == 500000 or xx == 1000000 or xx == 2000000 or xx == 3000000):\n",
    "#        print(xx)\n",
    "#    total = hh[j][0] + hh[j][1]\n",
    "#    hh[j][0] = hh[j][0] / total\n",
    "#    hh[j][1] = hh[j][1] / total\n",
    "        \n",
    "#fileTrain.close()\n",
    "winsound.Beep(450, 2000)\n",
    "#------------------------------------------------------\n",
    "fileTrain = data\n",
    "Y_TRAIN = []\n",
    "X_TRAIN = []\n",
    "    \n",
    "xx = 0\n",
    "for line in fileTrain:\n",
    "    xx = xx + 1\n",
    "    if(xx == 10000 or xx == 50000 or xx == 200000 or xx == 500000 or xx == 1000000 or xx == 2000000 or xx == 3000000):\n",
    "        print(xx)\n",
    "    line = ast.literal_eval(line)\n",
    "    newInter = []\n",
    "    if(line[0] == \"\"):\n",
    "        locD[line[0]] = 0\n",
    "        location = 0\n",
    "    else:\n",
    "        if(not(line[0] in locD)):\n",
    "            lc = lc + 1\n",
    "            locD[line[0]] = lc\n",
    "            location = lc\n",
    "        else:\n",
    "            location = locD[line[0]]\n",
    "    time1 = line[4]\n",
    "    time1 = time1.split(\" \")\n",
    "    if(not(time1[0] in dayD)):\n",
    "        dc = dc + 1\n",
    "        dayD[time1[0]] = dc\n",
    "        day = dc\n",
    "    else:\n",
    "        day = dayD[time1[0]]\n",
    "    if(not(time1[1] in monthD)):\n",
    "        mc = mc + 1\n",
    "        monthD[time1[1]] = mc\n",
    "        month = mc\n",
    "    else:\n",
    "        month = monthD[time1[1]]\n",
    "    dayNumber = int(time1[2])\n",
    "    followC = int(line[1])\n",
    "    friendC = int(line[2])\n",
    "    if(not(line[4] in langue)):\n",
    "        lanC = lanC + 1\n",
    "        langue[line[4]] = lanC\n",
    "        lang = lanC\n",
    "    description = getTagsHandles(line[3])\n",
    "    for jj in description:\n",
    "        if(not(jj in hh)):\n",
    "            hhC = hhC + 1\n",
    "            hh[jj] = hhC\n",
    "        newInter = []\n",
    "        newInter.append(location)\n",
    "        newInter.append(day)\n",
    "        newInter.append(month)\n",
    "        newInter.append(dayNumber)\n",
    "        newInter.append(followC)\n",
    "        newInter.append(friendC)\n",
    "        newInter.append(lang)\n",
    "        newInter.append(hh[jj])\n",
    "    #hashtagsList = getTagsHandles(line[-2])\n",
    "    #sumHH = 0\n",
    "    #for jj in hashtagsList:\n",
    "    #    sumHH = sumHH + hh[jj][0] - hh[jj][1]\n",
    "    \n",
    "    #newInter.append(location)\n",
    "    #newInter.append(day)\n",
    "    #newInter.append(month)\n",
    "    #newInter.append(dayNumber)\n",
    "    #newInter.append(followC)\n",
    "    #newInter.append(friendC)\n",
    "    #newInter.append(lang)\n",
    "    #newInter.append(sumHH)\n",
    "        \n",
    "    #print(newInter)\n",
    "    X_TRAIN.append(newInter)\n",
    "    Y_TRAIN.append(int(line[-1]))\n",
    "        \n",
    "#fileTrain.close()\n",
    "winsound.Beep(450, 2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ftiaxnw to csv arxeio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "50000\n",
      "200000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------\n",
    "fileTest = open(\"clinton_trump_kaggle_test.txt\", \"r\")\n",
    "#Y_TEST = []\n",
    "X_TEST = []\n",
    "idUsers = []\n",
    "    \n",
    "xx = 0\n",
    "for line in fileTest:\n",
    "    xx = xx + 1\n",
    "    if(xx == 10000 or xx == 50000 or xx == 200000 or xx == 500000 or xx == 1000000 or xx == 2000000 or xx == 3000000):\n",
    "        print(xx)\n",
    "    line = line.replace('\\n', \"\")\n",
    "    splittedTweet = line.split(\"\\t\")\n",
    "    userID = splittedTweet[2]\n",
    "    idUsers.append(userID)\n",
    "    location = splittedTweet[5]\n",
    "    followeCount = splittedTweet[3]\n",
    "    frinedCount = splittedTweet[4]\n",
    "    description = splittedTweet[6]\n",
    "    createdAT = splittedTweet[7]\n",
    "    lan = splittedTweet[9]\n",
    "    text = splittedTweet[-1]\n",
    "    line = [location, followeCount, frinedCount, description, createdAT, lan, text]\n",
    "    newInter = []\n",
    "    if(line[0] in locD):\n",
    "        location = locD[line[0]]\n",
    "    else:\n",
    "        lc = lc + 1\n",
    "        locD[line[0]] = lc\n",
    "        location = lc\n",
    "    time1 = line[4]\n",
    "    time1 = time1.split(\" \")\n",
    "    if(time1[0]in dayD):\n",
    "        day = dayD[time1[0]]\n",
    "    else:\n",
    "        dc = dc + 1\n",
    "        dayD[time1[0]] = dc\n",
    "        day = dc\n",
    "    if(time1[1] in monthD):\n",
    "        month = monthD[time1[1]]\n",
    "    else:\n",
    "        mc = mc + 1\n",
    "        monthD[time1[1]] = mc\n",
    "        month = mc\n",
    "    dayNumber = int(time1[2])\n",
    "    fc = int(line[1])\n",
    "    fcount = int(line[2])\n",
    "    if(line[-2] in langue):\n",
    "        lanCount = langue(line[-2])\n",
    "    else:\n",
    "        lanCount = 0\n",
    "    #hashtagsList = getTagsHandles(line[-2])\n",
    "    #sumHH = 0\n",
    "    #for jj in hashtagsList:\n",
    "    #    if(jj in hh):\n",
    "    #        sumHH = sumHH + hh[jj][0] - hh[jj][1]\n",
    "    #    else:\n",
    "    #        continue\n",
    "            \n",
    "    newInter.append(location)\n",
    "    newInter.append(day)\n",
    "    newInter.append(month)\n",
    "    newInter.append(dayNumber)\n",
    "    newInter.append(fc)\n",
    "    newInter.append(fcount)\n",
    "    newInter.append(lanCount)\n",
    "    #newInter.append(sumHH)\n",
    "        \n",
    "    #print(newInter)\n",
    "    X_TEST.append(newInter)\n",
    "    #Y_TEST.append(int(line[-1]))\n",
    "        \n",
    "fileTest.close()\n",
    "winsound.Beep(450, 2000)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "#decision tree\n",
    "start = time.clock()\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X_TRAIN, Y_TRAIN)\n",
    "Y_PRED = dtree.predict(X_TEST)\n",
    "end = time.clock()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddd = {}\n",
    "\n",
    "for i in range(len(idUsers)):\n",
    "    if(not(idUsers[i] in ddd)):\n",
    "        ddd[idUsers[i]] = Y_PRED[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15176\n"
     ]
    }
   ],
   "source": [
    "print(len(ddd))\n",
    "Y_P = []\n",
    "ID_P = []\n",
    "\n",
    "for i in ddd:\n",
    "    ID_P.append(i)\n",
    "    Y_P.append(ddd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('results.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(ID_P)):\n",
    "        writer.writerow({'id': str(ID_P[i]), 'label': str(1)})\n",
    "    \n",
    "#file.close()\n",
    "winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import sklearn.utils as utils\n",
    "\n",
    "v = DictVectorizer()\n",
    "D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
    "X = v.fit_transform(D)\n",
    "y = [0, 1]\n",
    "sel = SelectKBest(chi2, k=2)\n",
    "X_new = sel.fit_transform(X, y)\n",
    "X_new, y = utils.shuffle(X, y, random_state=1)\n",
    "#lr_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "#Y_PRED = lr_clf.predict(X_TEST)\n",
    "#winsound.Beep(450, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import sklearn.utils as utils\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(y[30:65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download was incomplete, downloading again.\n",
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d9b88eb8261e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'alt.atheism'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'soc.religion.christian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtwenty_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\twenty_newsgroups.py\u001b[0m in \u001b[0;36mfetch_20newsgroups\u001b[0;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing)\u001b[0m\n\u001b[1;32m    223\u001b[0m                         \"This may take a few minutes.\")\n\u001b[1;32m    224\u001b[0m             cache = download_20newsgroups(target_dir=twenty_home,\n\u001b[0;32m--> 225\u001b[0;31m                                           cache_path=cache_path)\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'20Newsgroups dataset not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\twenty_newsgroups.py\u001b[0m in \u001b[0;36mdownload_20newsgroups\u001b[0;34m(target_dir, cache_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Decompressing %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r:gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[1;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0;32m-> 2003\u001b[0;31m                          numeric_owner=numeric_owner)\n\u001b[0m\u001b[1;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[1;31m# Reverse sort directories.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2043\u001b[0m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[1;32m   2044\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                                  numeric_owner=numeric_owner)\n\u001b[0m\u001b[1;32m   2046\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrorlevel\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1, 1: 1, 2: 1, 3: 1})\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
